{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChessML Netz\n",
    "\n",
    "This neural network based on PyTorch will try to classifiy chess pieces from photos taken from the top of a chessboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a normalization function for the analyzed data\n",
    "\n",
    "The values are recommended by a PyTorch tutorial (https://youtu.be/32lHVbT09h8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First defining a sampler for development, so that we don't have to load all the data everytime we run the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "n_training_samples = 1000\n",
    "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
    "\n",
    "#Validation\n",
    "n_val_samples = 20\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
    "\n",
    "#Test\n",
    "n_test_samples = 4\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "train_set = torchvision.datasets.ImageFolder(root=\"./data/binary/train\",\n",
    "                                             transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           #sampler=train_sampler\n",
    "                                           )\n",
    "\n",
    "# Validation Data\n",
    "val_set = torchvision.datasets.ImageFolder(root=\"./data/binary/validation\",\n",
    "                                           transform=train_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                         batch_size=4,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=2,\n",
    "                                         #sampler=val_sampler\n",
    "                                         )\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(\"./data/validation\",\n",
    "                                             transform=train_transform)\n",
    "test_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2,\n",
    "                                          #sampler=val_sampler\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining classes\n",
    "\n",
    "bb = Black Bishop\n",
    "bk = Black King\n",
    "bn = Black Knight\n",
    "bp = Black Pawn\n",
    "bq = Black Queen\n",
    "br = Black Rook\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"bb\", \"bk\", \"bn\", \"bp\", \"bq\", \"br\",\"empty\", \"wb\", \"wk\", \"wn\", \"wp\", \"wq\", \"wr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "        # Defining the convolutional layers of the net\n",
    "        self.conv1 = nn.Conv2d(3, 12, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(12, 24, kernel_size=5)\n",
    "        \n",
    "        # self.dropout = nn.Dropout()\n",
    "\n",
    "        # Defining the fully connected layers of the net\n",
    "        self.fc1 = nn.Linear(600, 64)  \n",
    "        self.fc2 = nn.Linear(64, 13)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)  # Relu because it's famous\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(-1, 600)  # Convert 2d data to 1d\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    with progressbar.ProgressBar(max_value=len(train_loader)) as bar:\n",
    "        for i, t_data in enumerate(train_loader):\n",
    "            data, target = t_data\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            out = model(data)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            bar.update(i)\n",
    "            if i % 2000 == 1999:\n",
    "                print(\"Loss:\", running_loss / 2000)\n",
    "                running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, epoch=0):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(len(classes)))\n",
    "    class_total = list(0. for i in range(len(classes)))\n",
    "    predictions_for_class = [[0] for i in range(len(classes))] \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            out = model(data)\n",
    "            _, prediction = torch.max(out.data, 1)\n",
    "            total += target.size(0)\n",
    "            if torch.cuda.is_available():\n",
    "                correct += prediction.eq(target).sum().cpu().item()\n",
    "            else:\n",
    "                correct += prediction.eq(target).sum().item()\n",
    "                \n",
    "            c = (prediction == target).squeeze()\n",
    "            for i in range(target.size(0)):\n",
    "                label = target[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    print(\"\\nValidation\")\n",
    "    print(\"###################################\")\n",
    "    print(\"Epoch\", epoch)\n",
    "    print(\"Accuracy: %f\" % (100 * correct / total))\n",
    "    print(\"###################################\\n\")\n",
    "    for i in range(len(classes)):\n",
    "        try:\n",
    "            print('Accuracy of %5s : %2d %% [%2d/%2d]' % \n",
    "                  (classes[i], 100 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\n",
    "        except ZeroDivisionError:\n",
    "            print('No Accuracy for %s' % classes[i])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    \n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = dataiter.next()\n",
    "     \n",
    "    out = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(out, 1)\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print('   Actual: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The save model function will save the state of a model after a specific epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, epoch):\n",
    "    torch.save(model.state_dict(), \"model/chess-net_{}.pt\".format(epoch))\n",
    "    print(\"\\n------- Checkpoint saved -------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "Training and evaluating the ChessNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = ChessNet()\n",
    "    \n",
    "    # Activate cuda support if available\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Check if model is already available\n",
    "    # if os.path.isfile(\"model/chess-net.pt\"):\n",
    "    #    model = torch.load(\"model/chess-net.pt\")\n",
    "    \n",
    "    # Defining the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Defining the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # Start training\n",
    "    epochs = 20\n",
    "    start = time.time()\n",
    "    print(\"Starting training for %s epochs on %s\" % (epochs, time.ctime()))\n",
    "    for epoch in range(epochs):\n",
    "        train(model, epoch, optimizer, criterion)\n",
    "        validate(model, criterion, epoch)\n",
    "        save_model(model, epoch)\n",
    "    end = time.time()\n",
    "    print(\"Training of the neuroal network done.\")\n",
    "    print(\"Time spent:\", end-start, \"s\")\n",
    "    \n",
    "    # Testing the NN\n",
    "    print(\"\\nTest:\")\n",
    "    for i in range(4):\n",
    "        test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 20 epochs on Fri Mar  8 18:41:28 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10348 of 10348) |##################| Elapsed Time: 0:00:12 Time:  0:00:12\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-972361fa1b80>\", line 2, in <module>\n",
      "    main()\n",
      "  File \"<ipython-input-12-05dfe7c9820f>\", line 23, in main\n",
      "    train(model, epoch, optimizer, criterion)\n",
      "  File \"<ipython-input-7-2325408d5c87>\", line 17, in train\n",
      "    loss.backward()\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/site-packages/torch/tensor.py\", line 102, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 90, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/michaelwolz/Applications/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
