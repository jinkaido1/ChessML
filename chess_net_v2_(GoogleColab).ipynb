{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3iDzqMSF4dT",
    "colab_type": "text"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zJ-zfRF_GOjp",
    "colab_type": "code",
    "outputId": "09ed20e6-5dcd-4226-be6c-15128597a851",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR3j7RYyjFO1",
    "colab_type": "text"
   },
   "source": [
    "Now moving the GDrive Data to the local storage because it is way faster to read then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fdTpxM_BjM1s",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!mkdir /content/data\n",
    "!cp /content/drive/My\\ Drive/ChessNetData/data.tar.gz /content/data/\n",
    "!tar xzf /content/data/data.tar.gz -C /content/data/\n",
    "!rm /content/data/data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX6lUY5SH3VK",
    "colab_type": "text"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m-rd0m_AH59i",
    "colab_type": "code",
    "outputId": "757b9893-1b36-4052-824d-9a9efe678440",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Activating cuda support! ###\n",
      "\n",
      "=> Resuming training at epoch 12 with best-accuracy of: 99.00%\n",
      "Start training for 0 epochs on Thu Mar 28 13:16:18 2019\n",
      "Training of the model done.\n",
      "Time spent: 0.0001266002655029297 s\n",
      "Best-Accuracy: 99.00% after epoch 12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import time\n",
    "import progressbar\n",
    "import os\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Implementation based on resnet18\n",
    "# Accuracy of 99% after 12 Epochs of training with 31.200 training images and 7.800 validation images\n",
    "\n",
    "# Where to store the model\n",
    "MODELPATH = \"/content/drive/My Drive/ChessNetData/model/chess-net-v2-sgd.tar\"\n",
    "\n",
    "# Defining basic transform operations. Image size of 224x224 is required by underlying resnet\n",
    "# The normalization function based on the ImageNet data which was used to train the resnet model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Loading the training and validation data\n",
    "\n",
    "# Train Data\n",
    "train_set = torchvision.datasets.ImageFolder(root=\"/content/data/augmented/train\", transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=25, num_workers=2, shuffle=True, drop_last=True)\n",
    "\n",
    "# Validation Data\n",
    "val_set = torchvision.datasets.ImageFolder(root=\"/content/data/augmented/validation\", transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=25, num_workers=2, shuffle=True, drop_last=True)\n",
    "\n",
    "# Defining classes:\n",
    "# bb = Black Bishop\n",
    "# bk = Black King\n",
    "# bn = Black Knight\n",
    "# bp = Black Pawn\n",
    "# bq = Black Queen\n",
    "# br = Black Rook\n",
    "\n",
    "classes = (\"bb\", \"bk\", \"bn\", \"bp\", \"bq\", \"br\", \"empty\", \"wb\", \"wk\", \"wn\", \"wp\", \"wq\", \"wr\")\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    with progressbar.ProgressBar(max_value=len(train_loader)) as bar:\n",
    "        for i, t_data in enumerate(train_loader):\n",
    "            data, target = t_data\n",
    "\n",
    "            # put data on the gpu if available\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            out = model(data)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            bar.update(i)\n",
    "            if i % 200 == 199:\n",
    "                print(\" => Loss:\", running_loss / 200)\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "def validate(model, epoch=0):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(len(classes)))\n",
    "    class_total = list(0. for i in range(len(classes)))\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            # put data on the gpu if available\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            out = model(data)\n",
    "            _, prediction = torch.max(out.data, 1)\n",
    "            total += target.size(0)\n",
    "            if torch.cuda.is_available():\n",
    "                correct += prediction.eq(target).sum().cpu().item()\n",
    "            else:\n",
    "                correct += prediction.eq(target).sum().item()\n",
    "\n",
    "            c = (prediction == target).squeeze()\n",
    "            for i in range(target.size(0)):\n",
    "                label = target[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    print(\"\\nValidation\")\n",
    "    print(\"###################################\")\n",
    "    print(\"Epoch\", epoch)\n",
    "    print(\"Accuracy: %.2f%%\" % (100 * correct / total))\n",
    "    print(\"###################################\\n\")\n",
    "    for i in range(len(classes)):\n",
    "        try:\n",
    "            print('Accuracy of %5s : %2d%% [%2d/%2d]' %\n",
    "                  (classes[i], 100 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\n",
    "        except ZeroDivisionError:\n",
    "            print('No Accuracy for %s' % classes[i])\n",
    "    return correct / total  # Returning accuracy\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, epoch, best_acc):\n",
    "    # Saving a checkpoint of the training. This is essential for using the trained network and also to resume training\n",
    "    # if it stopped for some reason (e.g. limitations of Google Colab)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'bestacc': best_acc,\n",
    "    }, MODELPATH)\n",
    "    print(\"\\n------- Checkpoint saved -------\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    resume_training = True  # resuming training or starting a new one\n",
    "\n",
    "    model = models.resnet18(pretrained=True)  # use pretrained version of resnet18\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.require_grad = False  # freeze model to modify just the last layer of the nn\n",
    "\n",
    "    n_features = model.fc.in_features  # get the number of features for the new last layer\n",
    "\n",
    "    fc = nn.Sequential(\n",
    "        nn.Linear(n_features, 320),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(460, 13)  # one output for every class\n",
    "    )\n",
    "\n",
    "    model.classifier = fc\n",
    "\n",
    "    # Activate cuda support if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"### Activating cuda support! ###\\n\")\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Defining the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Defining the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Loading model for resuming training\n",
    "    starting_epoch = 0\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    if resume_training:\n",
    "        if os.path.exists(MODELPATH):\n",
    "            state = torch.load(MODELPATH)\n",
    "            model.load_state_dict(state[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
    "            starting_epoch = state[\"epoch\"]\n",
    "            best_acc = state[\"bestacc\"]\n",
    "            best_epoch = state[\"epoch\"]\n",
    "            print(\"=> Resuming training at epoch %d with best-accuracy of: %.2f%%\" % (starting_epoch, 100 * best_acc))\n",
    "    else:\n",
    "        if os.path.exists(MODELPATH):\n",
    "            answer = input(\"This will overwrite your existing model! Do you want to continue? [y, n]\")\n",
    "            if answer != 'y':\n",
    "                exit(0)\n",
    "        print(\"=> Starting first training of model\")\n",
    "\n",
    "    # Start training\n",
    "    epochs = 20  # amount of epochs for training\n",
    "    start = time.time()\n",
    "    print(\"Start training for %s epochs on %s\" % (epochs - starting_epoch, time.ctime()))\n",
    "    for epoch in range(starting_epoch, epochs):\n",
    "        train(model, optimizer, criterion)\n",
    "        acc = validate(model, epoch)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_epoch = epoch\n",
    "            save_model(model, optimizer, epoch, acc)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Training of the model done.\")\n",
    "    print(\"Time spent:\", end - start, \"s\")\n",
    "    print(\"Best-Accuracy: %.2f%% after epoch %d\" % (100 * best_acc, best_epoch))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "chess_net_v2.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
