{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChessML Netz\n",
    "\n",
    "This neural network based on PyTorch will try to classifiy chess pieces from photos taken from the top of a chessboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining all possible classes\n",
    "\n",
    "bb = Black Bishop\n",
    "bk = Black King\n",
    "bn = Black Knight\n",
    "bp = Black Pawn\n",
    "bq = Black Queen\n",
    "br = Black Rook\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"bb\", \"bk\", \"bn\", \"bp\", \"bq\", \"br\", \"wb\", \"wk\", \"wn\", \"wp\", \"wq\", \"wr\", \"empty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a normalization function for the analyzed data\n",
    "\n",
    "The values are recommended by a PyTorch tutorial (https://youtu.be/32lHVbT09h8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "        # Defining the convolutional layers of the net\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(6, 12, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(12, 24, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(24, 48, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(48, 96, kernel_size=3)\n",
    "\n",
    "        # Defining dropout layer to prevent from memorizing\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "\n",
    "        # Defining the fully connected layers of the net\n",
    "        self.fc1 = nn.Linear(384, 64)  # 96*2*2 = 384\n",
    "        self.fc2 = nn.Linear(64, 13)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)  # Relu because it's famous\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = x.view(-1, 384)  # Convert 2d data to 1d\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, train_data, optimizer):\n",
    "    model.train()\n",
    "    batch_id = 0\n",
    "\n",
    "    for data, target in train_data:\n",
    "        target = torch.Tensor(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        criterion = F.binary_cross_entropy\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_id * len(data), len(train_data) * len(data), 100. * batch_id / len(train_data), loss.item()\n",
    "        ))\n",
    "        batch_id = batch_id + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_data):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for data, target in eval_data:\n",
    "        target = torch.Tensor(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        out = model(data)\n",
    "        criterion = F.binary_cross_entropy\n",
    "        loss += criterion(out, target, size_average=False).item()\n",
    "        prediction = out.data.max(1, keepdim=True)[1]\n",
    "        if torch.cuda.is_available():\n",
    "            correct += prediction.eq(target.view_as(prediction)).cpu().sum()\n",
    "        else:\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum()\n",
    "            \n",
    "    loss = loss / len(eval_data)\n",
    "    print(\"###################################\")\n",
    "    print(\"Average loss:\", loss)\n",
    "    print(\"Accuracy:\", 100. * correct / len(eval_data))\n",
    "    print(\"###################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The test function is not really necessary. It is just for a better understanding and eventually testing the neural network manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, path):\n",
    "    model.eval()\n",
    "    files = os.listdir(path)\n",
    "    file = random.choice(files)\n",
    "    img = Image.open(os.path.join(path, file))\n",
    "    img_eval_tensor = transform(img)\n",
    "    img_eval_tensor.unsqueeze_(0)\n",
    "    if torch.cuda.is_available():\n",
    "        img_eval_tensor = img_eval_tensor.cuda()\n",
    "    out = model(img_eval_tensor)\n",
    "    print(out.data.max(1, keepdim=True))\n",
    "    img.show()\n",
    "    x = input(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "At first all available files are added to a file list. In addition the label of the file will be generated and added to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    file_list = []\n",
    "    for d in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, d)):\n",
    "            for f in os.listdir(os.path.join(path, d)):\n",
    "                file_list.append([os.path.join(path, d, f), hot_encode_label(d)])\n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating tensors from the file list, we just created. All files get mixed up randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tensors(file_list, batch_size):\n",
    "    train_data_list = []\n",
    "    train_data = []\n",
    "    label_list = []\n",
    "    files_count = len(file_list)\n",
    "    for i in range(files_count):\n",
    "        file = random.choice(file_list)\n",
    "        file_list.remove(file)\n",
    "        img = Image.open(file[0])  # Index 0: filename, Index 1: label\n",
    "        img_tensor = transform(img)\n",
    "        train_data_list.append(img_tensor)\n",
    "        label_list.append(file[1])\n",
    "        if len(train_data_list) >= batch_size:\n",
    "            train_data.append((torch.stack(train_data_list), label_list))\n",
    "            train_data_list = []\n",
    "            label_list = []\n",
    "            print(\"Loaded batch\", len(train_data), \"of\", int(files_count / batch_size))\n",
    "            print(\"Percentage Done:\", len(train_data) / int(files_count / batch_size) * 100, \"%\")\n",
    "            if len(train_data) >= 1:\n",
    "                break\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label will be hot encoded, since there is only one possible class for each tile of the chessboard. \n",
    "This means that for example a black knight will be labeled by the vector: \n",
    "\n",
    ">\\[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_label(label):\n",
    "    index = CLASSES.index(label)\n",
    "    vector = np.zeros(len(CLASSES), np.int8)\n",
    "    vector[index] = 1\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "Training and evaluating the ChessNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_list = read_files(\"data/train_augmented\")\n",
    "    train_data = generate_tensors(file_list, 64)\n",
    "\n",
    "    eval_files = read_files(\"data/eval_augmented\")\n",
    "    eval_data  = generate_tensors(file_list, 64)\n",
    "    \n",
    "    model = ChessNet()\n",
    "    # Activate cuda support if available\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Check if model is already available\n",
    "    # if os.path.isfile(\"model/chess-net.pt\"):\n",
    "    #     model = torch.load(\"model/chess-net.pt\")\n",
    "\n",
    "    # Defining the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    # optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(1,30):\n",
    "        train(model, epoch, train_data, optimizer)\n",
    "        evaluate(model, eval_data)\n",
    "        # test(model, \"data/train_augmented/bn\")\n",
    "        torch.save(model, \"model/chess-net.pt\")\n",
    "    print(\"Training of the neuroal network done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
